data_generation:
  random_seed: 42
  catalog: shm
  schema: mmm
  synthetic_data_table: synthetic_data

  start_date: 2020-01-01
  end_date: 2023-12-31

  outcome:
    name: sales
    intercept: 5.0
    sigma: 0.5
    scale: 100000

  media:
    adwords:
      beta: 1.5
      min: 5000
      max: 25000
      sigma: 1.0
      decay: true
      alpha: 0.6
      saturation: true
      mu: 2.5
    
    facebook:
      beta: 1.0
      min: 3000
      max: 15000
      sigma: 1.2
      decay: true
      alpha: 0.5
      saturation: true
      mu: 2.0
    
    linkedin:
      beta: 2.5
      min: 8000
      max: 35000
      sigma: 1.0
      decay: true
      alpha: 0.7
      saturation: true
      mu: 3.0

model:
  random_seed: 42
  catalog: shm
  schema: mmm
  data_table: synthetic_data
  outcome_name: sales
  outcome_scale: 100000
  sampling:
    draws: 1000
    tune: 500
    chains: 2
    target_accept: 0.95
  channels:
    adwords:
      beta_prior_sigma: 2.0
      has_adstock: true
      adstock_alpha_prior: 4.5
      adstock_beta_prior: 2.5
      has_saturation: true
      saturation_k_prior_mean: 0.5
      saturation_s_prior_alpha: 3.0
      saturation_s_prior_beta: 3.0
    facebook:
      beta_prior_sigma: 2.0
      has_adstock: true
      adstock_alpha_prior: 4.0
      adstock_beta_prior: 3.0
      has_saturation: true
      saturation_k_prior_mean: 0.5
      saturation_s_prior_alpha: 3.0
      saturation_s_prior_beta: 3.0
    linkedin:
      beta_prior_sigma: 2.0
      has_adstock: true
      adstock_alpha_prior: 5.0
      adstock_beta_prior: 2.0
      has_saturation: true
      saturation_k_prior_mean: 0.5
      saturation_s_prior_alpha: 3.0
      saturation_s_prior_beta: 3.0
  priors:
    intercept_mu: 5.0
    intercept_sigma: 2.0
    sigma_alpha: 2.0
    sigma_beta: 2.0
  mlflow:
    experiment_name: /mmm/model_experiments
    run_name: mmm_baseline

agent:
  random_seed: 42
  catalog: shm
  schema: mmm
  historical_data_table: synthetic_data
  model_path: /dbfs/mmm/models/latest_idata.nc
  dspy:
    llm_model: databricks-meta-llama-3-1-70b-instruct
    max_tokens: 2048
    temperature: 0.1
  channels:
    adwords:
      min_spend: 5000
      max_spend: 100000
      current_spend: 15000
    facebook:
      min_spend: 3000
      max_spend: 80000
      current_spend: 10000
    linkedin:
      min_spend: 8000
      max_spend: 120000
      current_spend: 20000
  optimization:
    default_budget: 150000
    min_allocation_pct: 0.1
    max_allocation_pct: 0.6
    optimization_periods: 30
  forecasting:
    default_periods: 30
    confidence_level: 0.95